{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "# To make data visualisations display in Jupyter Notebooks \n",
    "import numpy as np   # linear algebra\n",
    "import pandas as pd  # Data processing, Input & Output load\n",
    "import matplotlib.pyplot as plt # Visualization & plotting\n",
    "import datetime\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import joblib  #Joblib is a set of tools to provide lightweight pipelining in Python (Avoid computing twice the same thing)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "                                    # GridSearchCV - Implements a “fit” and a “score” method\n",
    "                                    # train_test_split - Split arrays or matrices into random train and test subsets\n",
    "                                    # cross_val_score - Evaluate a score by cross-validation\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, precision_score, make_scorer, accuracy_score, roc_curve, confusion_matrix, classification_report\n",
    "                                    # Differnt metrics to evaluate the model \n",
    "\n",
    "import warnings   # To avoid warning messages in the code run\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_train_actual, train_pred_prob, y_test_actual, test_pred_prob, *args):\n",
    "    '''\n",
    "    Generate the train & test roc curve\n",
    "    '''\n",
    "\n",
    "    AUC_Train = roc_auc_score(y_train_actual, train_pred_prob)\n",
    "    AUC_Test = roc_auc_score(y_test_actual, test_pred_prob)\n",
    "\n",
    "    if len(args) == 0:\n",
    "        print(\"Train AUC = \", AUC_Train)\n",
    "        print(\"Test AUC = \", AUC_Test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_train_actual, train_pred_prob)\n",
    "        fpr_tst, tpr_tst, thresholds = roc_curve(y_test_actual, test_pred_prob)\n",
    "        roc_plot(fpr, tpr, fpr_tst, tpr_tst)\n",
    "\n",
    "    else:\n",
    "        AUC_Valid = roc_auc_score(args[0], args[1])\n",
    "        print(\"Train AUC = \", AUC_Train)\n",
    "        print(\"Test AUC = \", AUC_Test)\n",
    "        print(\"Validation AUC = \", AUC_Valid)\n",
    "        fpr, tpr, thresholds = roc_curve(y_train_actual, train_pred_prob)\n",
    "        fpr_tst, tpr_tst, thresholds = roc_curve(y_test_actual, test_pred_prob)\n",
    "        fpr_val, tpr_val, thresholds = roc_curve(args[0], args[1])\n",
    "        roc_plot(fpr, tpr, fpr_tst, tpr_tst, fpr_val, tpr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(fpr, tpr, fpr_tst, tpr_tst, *args):\n",
    "    '''\n",
    "    Generates roc plot\n",
    "    '''\n",
    "\n",
    "    fig = plt.plot(fpr, tpr, label='Train')\n",
    "    fig = plt.plot(fpr_tst, tpr_tst, label='Test')\n",
    "\n",
    "    if len(args) == 0:\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.title(\"ROC curve using \")\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        fig = plt.plot(args[0], args[1], label='Validation')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.title(\"ROC curve using \")\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in the dataset\n",
    "Insurance_Data = pd.read_csv('carInsurance_train.csv')\n",
    "print('Train Data Shape - ', Insurance_Data.shape)\n",
    "Insurance_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of values are stored in the columns?\n",
    "Insurance_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some statistical information about our dataframe.\n",
    "Insurance_Data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we can get summary for the categorical data\n",
    "Insurance_Data.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = 'CarInsurance'\n",
    "pd.crosstab(Insurance_Data[Target], columns='N', normalize=True)\n",
    "# pd.crosstab(Insurance_Data[Target], columns='N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count every row of class 1 as 2 rows of Class 1\n",
    "0.599/0.401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = Insurance_Data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_num_cols = Insurance_Data.select_dtypes(exclude=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop columns which we will not use\n",
    "num_cols = Insurance_Data.drop(['Id', 'CarInsurance'],axis=1).select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_num_cols = Insurance_Data.drop(['CallStart', 'CallEnd'],axis=1).select_dtypes(exclude=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Numeric Columns \\n', num_cols)\n",
    "print('Non-Numeric Columns \\n', non_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets drop CarLoan, HHInsurance, Default from the numeric columns as these are dummies\n",
    "num_cols_viz = ['DaysPassed', 'Age', 'NoOfContacts', 'PrevAttempts', 'LastContactDay', 'Balance']\n",
    "\n",
    "fig, axes = plt.subplots(3,2,sharex=False,sharey=False, figsize=(15,15))\n",
    "Insurance_Data.loc[:,[Target]+num_cols_viz].boxplot(by=Target, ax=axes, return_type='axes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_num_cols_viz = non_num_cols+['CarLoan', 'HHInsurance', 'Default']\n",
    "fig, axes = plt.subplots(len(non_num_cols_viz),sharex=False,sharey=False, figsize=(15,50))\n",
    "for i in range(len(non_num_cols_viz)):\n",
    "    pd.crosstab(Insurance_Data[non_num_cols_viz[i]], Insurance_Data[Target]).plot(kind='bar', \n",
    "                                                                                  stacked=True, \n",
    "                                                                                  grid=False, \n",
    "                                                                                  ax=axes[i],\n",
    "                                                                                  rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data_Org = Insurance_Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data['Job'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data['Job'] = Insurance_Data['Job'].fillna('None')\n",
    "Insurance_Data['Job'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data['Job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing education with the most common education level by job type\n",
    "\n",
    "# Create job-education level mode mapping\n",
    "edu_mode=[]\n",
    "\n",
    "# What are different Job Types\n",
    "job_types = Insurance_Data.Job.value_counts().index\n",
    "job_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now according to the job type we will crate a mapping where the job and mode of education is there.\n",
    "# It means when there are many people in the managment job then most of them are in which education.\n",
    "# We can find that in below mapping\n",
    "\n",
    "for job in job_types:\n",
    "    mode = Insurance_Data[Insurance_Data.Job==job]['Education'].value_counts().nlargest(1).index\n",
    "    edu_mode = np.append(edu_mode,mode)\n",
    "edu_map=pd.Series(edu_mode,index=Insurance_Data.Job.value_counts().index)\n",
    "\n",
    "edu_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to missing education obs. We will replace education now by jobs value\n",
    "for j in job_types:\n",
    "    Insurance_Data.loc[(Insurance_Data['Education'].isnull()) & (Insurance_Data['Job']==j),'Education'] = edu_map.loc[edu_map.index==j][0]\n",
    "\n",
    "# For those who are not getting mapped we will create a new category as None\n",
    "Insurance_Data['Education'].fillna('None',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing communication with none \n",
    "Insurance_Data['Communication'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data['Communication'] = Insurance_Data['Communication'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing value in Outcome\n",
    "Insurance_Data['Outcome'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing outcome as not in previous campaign, we are adding one category to Outcome\n",
    "# We will add category if the value of DaysPassed is -1\n",
    "\n",
    "Insurance_Data.loc[Insurance_Data['DaysPassed']==-1,'Outcome']= 'NoPrev'\n",
    "Insurance_Data['Outcome'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have any missing values left\n",
    "Insurance_Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data_num = Insurance_Data[num_cols+['Id', 'CarInsurance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns data\n",
    "Insurance_Data_cat = Insurance_Data[non_num_cols]\n",
    "non_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies\n",
    "Insurance_Data_cat_dummies = pd.get_dummies(Insurance_Data_cat)  #One-Hot Embedding\n",
    "print(Insurance_Data_cat_dummies.shape)\n",
    "Insurance_Data_cat_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insurance_Data_final = pd.concat([Insurance_Data_num, Insurance_Data_cat_dummies], axis=1)\n",
    "print(Insurance_Data_final.shape)\n",
    "Insurance_Data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there are missing values before we run model\n",
    "Insurance_Data_final.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = Insurance_Data_final.drop(['Id', 'CarInsurance'], axis=1) #X\n",
    "train_label = Insurance_Data_final['CarInsurance'] #y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_state is the seed used by the random number generator. It can be any integer.\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, train_label, train_size=0.7 , stratify=train_label, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 10 rows of data, 7 rows class 0, 3 rows class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70-30 split, random splitting, train will have 7 rows(class 0), test will have 3 rows(class 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify option will make sure that train has both the classes, and also test has both the classes in 70-30\n",
    "# Guarantee that:\n",
    "# train 7 rows(5 rows class 0, 2 rows class 1)\n",
    "# test 3 rows (2 rows class 0, 1 row of class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape[0]) # 2800, 1123 are 1s and the rest (2800-1123=1677) 0s\n",
    "print(np.sum(y_train))\n",
    "print(y_test.shape[0]) # 1200, 481 are 1s and the rest (1200-481=719) 0s\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train shape - ', X_train.shape)\n",
    "print('Test shape  - ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model parameters to tune\n",
    "model_parameters = {\n",
    "        'kernel':['rbf'], #['rbf', 'poly', 'linear', 'sigmoid']\n",
    "        'C': [1], # [0, 1, 10, 100, 1000, 1e15] C is reciprocal of Lambda, strength of Lambda; \n",
    "# Lambda = 0(Plain Logistic Regression (Term 1), No Regularization), C = 1/0, feed very very big number to C (1e15)\n",
    "# Lambda = Very big number(Heavy Regularization, weights will almost die,0), C = 1/inf, C = 0\n",
    "        'class_weight': ['balanced'], #['balanced', None]\n",
    "        'gamma': [0.0001] #[0.0001, 'scale', 'auto']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch the parameters to find the best parameters.\n",
    "model = SVC(probability=True, random_state=33)  # Support vector classifier\n",
    "\n",
    "gscv = GridSearchCV(estimator=model, \n",
    "                    param_grid=model_parameters, \n",
    "                    cv=3,  # 3-Fold Cross Validation\n",
    "#                     10 fold 2520, 280\n",
    "                    verbose=3, #To print what it is doing\n",
    "                    n_jobs=-1, #fastest possible depending in the laptop\n",
    "                    scoring='roc_auc') #tell us 1 f1-score per combination\n",
    "# scoring='roc_auc' (Almost always try that.)\n",
    "\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best parameter are -', gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gscv.best_score_)\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.scorer_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC on test by gscv =', roc_auc_score(y_true=y_test,\n",
    "                                                        y_score=gscv.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "# y_pred y_test\n",
    "# 1       1\n",
    "# 0       1\n",
    "# 1       0\n",
    "# 1       1\n",
    "# 1       0\n",
    "\n",
    "# Precision class 1 = 2/4 = 0.5\n",
    "# Recall class 1 = 2/3 = 0.66\n",
    "\n",
    "# f1-score = 2PR/(P+R)\n",
    "\n",
    "# Precision class 0 = 0/1 = 0\n",
    "# Recall class 0 = 0/2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ROC\n",
    "plt.subplots(figsize=(10, 5))\n",
    "train_prob = gscv.predict_proba(X_train)[:, 1]\n",
    "test_prob = gscv.predict_proba(X_test)[:, 1]\n",
    "\n",
    "plot_roc_curve(y_train, train_prob,\n",
    "               y_test, test_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
